{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A COVID-19 Analysis (week 5 report)\n",
    "\n",
    "## Background\n",
    "\n",
    "Based on the information at the [Pan-American Health Organization site](https://www.paho.org/bra/index.php?option=com_content&view=article&id=6101:covid19&Itemid=875):\n",
    "\n",
    "\n",
    "    The World Health Organization (WHO) declared, on January 30, 2020, that the outbreak of the disease caused by the new coronavirus (COVID-19) constitutes a Public Health Emergency of International Importance - the Organization's highest alert level, as provided at the International Health Regulations. On March 11, 2020, COVID-19 was characterized by WHO as a pandemic.\n",
    "\n",
    "## The problem\n",
    "\n",
    "Through the data analysis I'll try to show the main epicenters of virus discemination and the places that are potencially related to that problem, but to be more  concise and practical, the analysis will be centered in the city that I live, SÃ£o Paulo.  \n",
    "\n",
    "Because the theme is so delicate, I'm not trying to take any precipitated conclusions nor find any guilted subjects.  \n",
    "At the end of the work I hope that the audience could take their own decisions with a little more knowledge over the situation.  \n",
    "\n",
    "## The data\n",
    "\n",
    "In that work I'll try to explore some datasets related with the virus and the disease that it causes. \n",
    "The main data, used in the analysis, will be downloaded from the government sites, but some information (related to the districts bondaries) are downloaded from other sources and previous stored on my GitHub account.  \n",
    "\n",
    "##### Demografic data:\n",
    "https://www.prefeitura.sp.gov.br/cidade/secretarias/subprefeituras/subprefeituras/dados_demograficos/index.php\n",
    "\n",
    "This data will be obtained using BeaultifulSoup as data scraping tool.\n",
    "This data is relevant to us to demonstrate that the virus discemination is related to the populational density of the districts.\n",
    "\n",
    "##### District boundaries data:\n",
    "https://artefolha.carto.com/tables/distritos_sp/public/map\n",
    "\n",
    "\n",
    "The site offers a link to download the geojson of the city we're analysing.\n",
    "The data was downloaded and stored at my GitHub repository to be used on the Jupiter Notebook:\n",
    "https://raw.githubusercontent.com/UgoCesar19/Coursera_Capstone/master/distritos_sp.geojson\n",
    "\n",
    "That data will be used to plot the populational density, using cloropleth map with folium.\n",
    "\n",
    "##### Covid data:\n",
    "https://opendatasus.saude.gov.br/dataset/casos-nacionais\n",
    "\n",
    "This is the core of this work.\n",
    "This is the government data about Flu Syndrome, and tests on COVID-19.\n",
    "The data have been updated from monday to fryday.\n",
    "We'll usse that data to discover the number of confirmed cases, by week, by day, by neighborhood, and to obtain the geospatial data through geopy.\n",
    "\n",
    "##### Venues data:\n",
    "Here we'll use the [Foursquare API](https://developer.foursquare.com/places) to obtain the main places among each neighborhood that reported COVID-19 cases that are potentially active.  \n",
    "\n",
    "## Metodology\n",
    "\n",
    "First we scrape the government demographic data, showing the districts with the most populational density on a cloropleth map.\n",
    "\n",
    "![alt text](https://raw.githubusercontent.com/UgoCesar19/Coursera_Capstone/master/populational%20density.png \"Pupulational Density\")\n",
    "\n",
    "Then we present an basic panorama about historical data on COVID-19, showing number of confirmed cases by week, and number of potentially active cases by day.  \n",
    "\n",
    "![alt text](https://raw.githubusercontent.com/UgoCesar19/Coursera_Capstone/master/confirmed%20cases%20by%20week.png \"Confirmed cases per week\")\n",
    "\n",
    "\n",
    "![alt text](https://raw.githubusercontent.com/UgoCesar19/Coursera_Capstone/master/confirmed%20cases%20by%20day.png \"Potentially active cases per day\")\n",
    "\n",
    "\n",
    "After that the analysis will took the path of relating the city demografic data with geospatial data about the virus discemination, foccusing on potetially active cases.  \n",
    "\n",
    "With that in mind we try to determine the main epicenter of the virus in the city. At this point, because the Flu Syndrome is a huge dataset composed by the government from various sources, we have a lot of noise. Many of the the neighborhoods found using geopy doesn't pertain to the city we're analysing:  \n",
    "\n",
    "![alt text](https://raw.githubusercontent.com/UgoCesar19/Coursera_Capstone/master/active%20cases%20noise.png \"Data noise\")\n",
    "\n",
    "\n",
    "Because of the noise and the geospatial nature of the data we choose DBSCAN (Density Based Spatial Clustering of Aplications With Noise) as the machine learning algoritm to explore and understand the neighborhood data.  \n",
    "\n",
    "Eliminating the noise and grouping the cases by cluster we could determine the main epicenter in the city. We break this process into two clusterization steps.  \n",
    "\n",
    "The first will lead us to the data related to our city.  \n",
    "\n",
    "![alt text](https://raw.githubusercontent.com/UgoCesar19/Coursera_Capstone/master/first%20clusterization.png \"First clusteriztion\")\n",
    "\n",
    "\n",
    "The second will spot the main epicenter inside city area.  \n",
    "\n",
    "![alt text](https://raw.githubusercontent.com/UgoCesar19/Coursera_Capstone/master/second%20clusterization.png \"Second clusteriztion\")\n",
    "\n",
    "\n",
    "At that point, we use the Foursquare API to search by venues that are potentially related to virus discemination near the epicenter.\n",
    "\n",
    "![alt text](https://raw.githubusercontent.com/UgoCesar19/Coursera_Capstone/master/venues%20found.png \"Venues found\")\n",
    "\n",
    "\n",
    "Lastly we present the main kinds of venues potencially related to virus discemination, and present the main neighborhoods with virus discemination on the epicenter along with the places near that neighborhoods.  \n",
    "\n",
    "![alt text](https://raw.githubusercontent.com/UgoCesar19/Coursera_Capstone/master/main%20neighborhoods%20and%20venues.png \"Venues found\")\n",
    "\n",
    "\n",
    "## Results\n",
    "\n",
    "It's important to state that at the moment of this publication (07/2020) the crisis around the COVID-19 is in course, so the data could and will change across the days and, the conclusions about that will evolve too.  \n",
    "The intention is that this analysis continues to be made as a tool to spot the problem that are evolving.\n",
    "\n",
    "## Discussion\n",
    "\n",
    "The important thing about that analysis is that we're using the data to make our conclusions, despite of the battle involving the media and the government.  \n",
    "\n",
    "I think that the government could learn with that problem to invest more in health and better prepare the country infraestruture, so in the future we could meke important decisions in less time, before the things come at the point we are now.  \n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Again, becouse this is a delicate theme, I like to keep this work as an evolving piece and wait for feedback, to better the analysis.  \n",
    "\n",
    "Other thing is that, althoug this work toke the path that I choose, I hope that other analysts could use that as an example and make their own analysis.  \n",
    "\n",
    "I hope too that people could better take their own decisions based on my study. Everyone could help, especially if they are well informed.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
